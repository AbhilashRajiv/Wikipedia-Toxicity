{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n",
       "1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n",
       "2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n",
       "3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n",
       "4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data using read_csv function from pandas package\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\practise files\\NLP\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "comment_text    0\n",
       "toxic           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            5000 non-null   object\n",
      " 1   comment_text  5000 non-null   object\n",
      " 2   toxic         5000 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barnstar', 'defender', 'wiki', 'barnstar', 'like']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "\n",
    "i_p=r'(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'\n",
    "U_rl=r'((\\w+)://([\\w\\-\\.]+)/(\\w+).(\\w+))'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocessing(DataFrame):\n",
    "    global t\n",
    "    t=DataFrame.comment_text\n",
    "    for i in range(DataFrame.shape[0]):\n",
    "        t[i]=re.sub(i_p,\"\",t[i])\n",
    "        t[i]=re.sub(U_rl,\"\",t[i])\n",
    "        t[i]=re.sub(\"'\",\"\",t[i])\n",
    "        t[i]=re.sub(\"''\",\"\",t[i])\n",
    "        t[i]=re.sub(r'\\d+', '', t[i])\n",
    "        t[i]=re.sub(r'[^\\w\\s]','',t[i])\n",
    "        t[i] = re.sub(r'_','',t[i])\n",
    "        t[i]=t[i].lower()\n",
    "        t[i]=word_tokenize(t[i])\n",
    "        t[i]=[words for words in t[i] if words not in stop_words]\n",
    "        t[i] =[p for p in t[i] if p not in string.punctuation]\n",
    "        t[i]=[lemmatizer.lemmatize(words) for words in t[i]]\n",
    "        \n",
    "preprocessing(df)\n",
    "t[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a counter, find the top terms in the data\n",
    "\n",
    "most_common_words=[]\n",
    "def most_common_words_list(list_collection):\n",
    "    for word_list in list_collection:\n",
    "        for (word, count) in Counter(word_list).most_common():\n",
    "            if count>1:\n",
    "                most_common_words.append(word)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words_list(t)\n",
    "len(most_common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 425),\n",
       " ('page', 376),\n",
       " ('wikipedia', 238),\n",
       " ('please', 211),\n",
       " ('would', 180),\n",
       " ('talk', 178),\n",
       " ('one', 162),\n",
       " ('source', 131),\n",
       " ('dont', 123),\n",
       " ('like', 110)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(most_common_words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barnstar defender wiki barnstar like edit kayastha page let form solidarity group malign article subject matter propose folloing name group united intellectual front kayastha ethinicty racist castist abuse uifkearca'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=[\" \".join(lists) for lists in t]\n",
    "t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barnstar defender wiki barnstar like  kayastha  let form solidarity group malign  subject matter propose folloing name group united intellectual front kayastha ethinicty racist castist abuse uifkearca'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ELiminating contextual stopwords like “Wikipedia”, “page”, “edit” and those related to the same\n",
    "\n",
    "t=[re.sub(r\"article\\w*\",\"\",sentence) for sentence in t]\n",
    "t=[re.sub(r\"wikipedia\\w*\",\"\",sentence) for sentence in t]\n",
    "t=[re.sub(r\"edit\\w*\",\"\",sentence) for sentence in t]\n",
    "t=[re.sub(r\"page\\w*\",\"\",sentence) for sentence in t]\n",
    "t[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barnstar defender wiki barnstar like  kayastha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seems unbalanced whatever said mathsci said fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marya dzmitruk born minsk belarus march mother...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talkback dear celestia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new category honestly think need add category ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>dildo read response correctly never said going...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>calm calm dont get big dick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>opinion dougweller using privilege poorly pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>style section expanded didnt remember placed tag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>one agreement repulican joe hazelton wack mole...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxic\n",
       "0     barnstar defender wiki barnstar like  kayastha...      0\n",
       "1     seems unbalanced whatever said mathsci said fa...      0\n",
       "2     marya dzmitruk born minsk belarus march mother...      0\n",
       "3                                talkback dear celestia      0\n",
       "4     new category honestly think need add category ...      0\n",
       "...                                                 ...    ...\n",
       "4995  dildo read response correctly never said going...      0\n",
       "4996                        calm calm dont get big dick      1\n",
       "4997  opinion dougweller using privilege poorly pers...      0\n",
       "4998   style section expanded didnt remember placed tag      0\n",
       "4999  one agreement repulican joe hazelton wack mole...      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_text=t\n",
    "df.drop(columns=\"id\",inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4563\n",
       "1     437\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into train and test sets\n",
    "\n",
    "X=df.comment_text\n",
    "y=df.toxic\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1840    psyou really something life looked around user...\n",
       "2115                        cant cant create  best friend\n",
       "4437    blocked right posted suggested use time put ni...\n",
       "1146    ga review review transcluded talkitalian cruis...\n",
       "2486    please stop continue vandalize  blocked   plea...\n",
       "                              ...                        \n",
       "4426    yes accusation sock puppetry sock puppetry att...\n",
       "466     curiosity  personal attack include strawman at...\n",
       "3092    know got mutha fuckin charlie bronson must thi...\n",
       "3772                                    ok seriously hell\n",
       "860     go fuck bastard yyou life go fuck bastard yank...\n",
       "Name: comment_text, Length: 3500, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF values for the terms as feature to get into a vector space model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect=TfidfVectorizer(max_features=4000)\n",
    "X_train_vect=vect.fit_transform(X_train)\n",
    "X_test_vect=vect.transform(X_test)\n",
    "y_train=y_train.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3500x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 73448 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect=X_train_vect.toarray()\n",
    "X_test_vect=X_test_vect.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(4000,)),\n",
    "    Dense(15, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8927 - val_loss: 0.5358 - val_accuracy: 0.9038\n",
      "Epoch 2/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.9171 - val_loss: 0.3508 - val_accuracy: 0.9038\n",
      "Epoch 3/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9171 - val_loss: 0.2829 - val_accuracy: 0.9038\n",
      "Epoch 4/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9171 - val_loss: 0.2667 - val_accuracy: 0.9038\n",
      "Epoch 5/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9212 - val_loss: 0.2491 - val_accuracy: 0.9095\n",
      "Epoch 6/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9388 - val_loss: 0.2308 - val_accuracy: 0.9200\n",
      "Epoch 7/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9633 - val_loss: 0.2234 - val_accuracy: 0.9238\n",
      "Epoch 8/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9829 - val_loss: 0.2288 - val_accuracy: 0.9238\n",
      "Epoch 9/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9902 - val_loss: 0.2410 - val_accuracy: 0.9219\n",
      "Epoch 10/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9931 - val_loss: 0.2460 - val_accuracy: 0.9248\n",
      "Epoch 11/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9963 - val_loss: 0.2599 - val_accuracy: 0.9238\n",
      "Epoch 12/40\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9971 - val_loss: 0.2709 - val_accuracy: 0.9248\n",
      "Epoch 13/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9984 - val_loss: 0.2842 - val_accuracy: 0.9229\n",
      "Epoch 14/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.2972 - val_accuracy: 0.9229\n",
      "Epoch 15/40\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.3059 - val_accuracy: 0.9238\n",
      "Epoch 16/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.3161 - val_accuracy: 0.9238\n",
      "Epoch 17/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.3244 - val_accuracy: 0.9238\n",
      "Epoch 18/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.3387 - val_accuracy: 0.9238\n",
      "Epoch 19/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.3427 - val_accuracy: 0.9248\n",
      "Epoch 20/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.3544 - val_accuracy: 0.9238\n",
      "Epoch 21/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.3604 - val_accuracy: 0.9248\n",
      "Epoch 22/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.3658 - val_accuracy: 0.9248\n",
      "Epoch 23/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.3742 - val_accuracy: 0.9248\n",
      "Epoch 24/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.3798 - val_accuracy: 0.9248\n",
      "Epoch 25/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.3861 - val_accuracy: 0.9248\n",
      "Epoch 26/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.3983 - val_accuracy: 0.9229\n",
      "Epoch 27/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.4047 - val_accuracy: 0.9229\n",
      "Epoch 28/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.4030 - val_accuracy: 0.9248\n",
      "Epoch 29/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.4099 - val_accuracy: 0.9238\n",
      "Epoch 30/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.4140 - val_accuracy: 0.9248\n",
      "Epoch 31/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.4187 - val_accuracy: 0.9238\n",
      "Epoch 32/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.4228 - val_accuracy: 0.9238\n",
      "Epoch 33/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.4279 - val_accuracy: 0.9238\n",
      "Epoch 34/40\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.4305 - val_accuracy: 0.9238\n",
      "Epoch 35/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.4363 - val_accuracy: 0.9248\n",
      "Epoch 36/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4362 - val_accuracy: 0.9238\n",
      "Epoch 37/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4418 - val_accuracy: 0.9238\n",
      "Epoch 38/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4447 - val_accuracy: 0.9248\n",
      "Epoch 39/40\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4555 - val_accuracy: 0.9248\n",
      "Epoch 40/40\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4549 - val_accuracy: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dda473d760>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vect, y_train,\n",
    "batch_size=50, epochs=40, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 975us/step - loss: 0.3368 - accuracy: 0.9320\n",
      "[0.3368034064769745, 0.9319999814033508]\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test_vect,y_test))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loser cant block forever admin ego hippie freak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>block block call dumbhead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>there fucking wiki  insane person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fuck assfuck assfuck assfuck assfuck assfuck a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>christian becaue jesus assyrian woman tit assy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>ohcome guy nodq saw taping theyve never ever e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>agree sophys duckling whoever wrote america po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>sunshine quit asshole stating fact actually ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>yes complain rabbi go shoot defenseless arab t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>calm calm dont get big dick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxic\n",
       "7       loser cant block forever admin ego hippie freak      1\n",
       "8                             block block call dumbhead      1\n",
       "16                    there fucking wiki  insane person      1\n",
       "21    fuck assfuck assfuck assfuck assfuck assfuck a...      1\n",
       "23    christian becaue jesus assyrian woman tit assy...      1\n",
       "...                                                 ...    ...\n",
       "4933  ohcome guy nodq saw taping theyve never ever e...      1\n",
       "4953  agree sophys duckling whoever wrote america po...      1\n",
       "4977  sunshine quit asshole stating fact actually ap...      1\n",
       "4985  yes complain rabbi go shoot defenseless arab t...      1\n",
       "4996                        calm calm dont get big dick      1\n",
       "\n",
       "[437 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"toxic\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(vect.transform([df.loc[21][0]]).toarray())\n",
    "for val in y_pred:\n",
    "    if val<0.5:\n",
    "        print(0)\n",
    "    else:\n",
    "        print(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform([X_train[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building: Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')\n",
    "svc.fit(X_train_vect,y_train)\n",
    "y_pred=svc.predict(X_test_vect)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.948\n",
      "precision  0.9365079365079365\n",
      "recall  0.44360902255639095\n",
      "f1_score1  0.6020408163265306\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation: Accuracy, recall, and f1_score\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"accuracy \",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision \",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall \",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1_score1 \",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1367\n",
      "           1       0.94      0.44      0.60       133\n",
      "\n",
      "    accuracy                           0.95      1500\n",
      "   macro avg       0.94      0.72      0.79      1500\n",
      "weighted avg       0.95      0.95      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1367\n",
      "           1       0.64      0.65      0.64       133\n",
      "\n",
      "    accuracy                           0.94      1500\n",
      "   macro avg       0.80      0.81      0.80      1500\n",
      "weighted avg       0.94      0.94      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust the appropriate parameter in the SVC module to reduce the class imbalnce\n",
    "\n",
    "svc=SVC(kernel='linear',class_weight=\"balanced\")\n",
    "svc.fit(X_train_vect,y_train)\n",
    "y_pred=svc.predict(X_test_vect)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score1  0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score1 \",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid={'C': [i/100 for i in range(5,16,1)]}\n",
    "clf=GridSearchCV(estimator=svc,param_grid=param_grid, scoring= \"recall\",cv=skf) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(class_weight='balanced', kernel='linear'),\n",
       "             param_grid={'C': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       "                               0.13, 0.14, 0.15]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.14}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the parameters with the best recall in cross validation\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1367\n",
      "           1       0.66      0.72      0.69       133\n",
      "\n",
      "    accuracy                           0.94      1500\n",
      "   macro avg       0.82      0.84      0.83      1500\n",
      "weighted avg       0.94      0.94      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='linear',class_weight=\"balanced\", C=0.14)\n",
    "svc.fit(X_train_vect,y_train)\n",
    "y_pred=svc.predict(X_test_vect)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6881720430107527"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931407942238268"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and evaluate using the best estimator\n",
    "\n",
    "svc=SVC(kernel='linear',class_weight=\"balanced\", C=0.145)\n",
    "svc.fit(X_train_vect,y_train)\n",
    "y_pred=svc.predict(X_test_vect)\n",
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Pred_Toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>think bully course bully hate called anonymous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>back yeah know youre cahoot linux nutcase like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>seriously soon asim unbanened wll wreacfk ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>redneck shouldnt bad mouth nascar people think...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>fucking album cover fuck supposed know owns fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>stop im done people like keep talking bad thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>quit threatening beyotch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>assume horrible nigger yuck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>nigger nigger nigger nigger nigger nigger nigg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>adijapan delete ethymologie constantly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comments  Pred_Toxicity\n",
       "1600  think bully course bully hate called anonymous...              1\n",
       "794   back yeah know youre cahoot linux nutcase like...              1\n",
       "4767  seriously soon asim unbanened wll wreacfk ever...              1\n",
       "4628  redneck shouldnt bad mouth nascar people think...              1\n",
       "2633  fucking album cover fuck supposed know owns fu...              1\n",
       "4724  stop im done people like keep talking bad thin...              1\n",
       "4524                           quit threatening beyotch              1\n",
       "4209                        assume horrible nigger yuck              1\n",
       "742   nigger nigger nigger nigger nigger nigger nigg...              1\n",
       "3899             adijapan delete ethymologie constantly              1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the most prominent terms in the toxic comments\n",
    "\n",
    "d={\"Comments\":X_test,\"Pred_Toxicity\":y_pred}\n",
    "df1=pd.DataFrame(data=d)\n",
    "df1.loc[df1.Pred_Toxicity==1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agree asked add told likely deleted please talk contribs email'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_list=list(df1.Comments)\n",
    "toxic_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agree'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_list=[word_tokenize(sentence) for sentence in toxic_list]\n",
    "toxic_word_list=[word for sentence in toxic_list for word in sentence]\n",
    "toxic_word_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk', 327),\n",
       " ('please', 312),\n",
       " ('one', 277),\n",
       " ('nigger', 265),\n",
       " ('like', 259),\n",
       " ('would', 250),\n",
       " ('dont', 237),\n",
       " ('source', 219),\n",
       " ('see', 217),\n",
       " ('think', 205),\n",
       " ('must', 202),\n",
       " ('people', 201),\n",
       " ('also', 189),\n",
       " ('time', 189),\n",
       " ('im', 178)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(toxic_word_list).most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
